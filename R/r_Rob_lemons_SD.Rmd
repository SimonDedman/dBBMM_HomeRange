---
title: "Lemon sharks ecology Bimini"
author: "Sprinkles (Maurits van Zinnicq Bergmann) & Simon Dedman" 
date: "2021-09-07"
output:
  html_document: default
  pdf_document: default---
---

```{r clear_memory}
rm(list = ls())
```

## Data loading

Set the working directory depending on the user

```{r setup}
print(Sys.info()["nodename"])
if (grepl("aurits", Sys.info()["nodename"])) {
  data.dir <- "~/Documents/Science/Projects/Rob Bullock - Bimini/data/"
}
if (grepl("nautilus", Sys.info()["nodename"]) | grepl("Poseidon", Sys.info()["nodename"]) | grepl("aquarius", Sys.info()["nodename"])) {
  data.dir <- "/home/simon/Dropbox/PostDoc Work/Rob Bullock accelerometer Lemons 2020.09/"
}
```

Load libraries

```{r load_library,result='hide',message=F}
library(dplyr)
library(devtools)
# install_git('https://gitlab.com/bartk/move.git') #Installs 'move' development version
library(move)
library(ggplot2)
library(maptools)
library(circular)
library(ggmap)
library(mapproj)
library(knitr)
library(magrittr) # %<>%
library(tidyr) # drop_na
library(tidylog) # verbose functions
library(raster)
library(sf)
```

Load data set

```{r read_files}
DET <- read.csv(file.path(data.dir, "/TRACKS1.csv")) # 1308 x 7
```

Check data directory and create it if not present

```{r data directory}
# set path to general folder where output files will be written
out.dir <- "dBBMM ASCII/"
if (!dir.exists(data.dir)) {
  stop(paste0(
    "Directory not found: \n",
    "       ", gsub("\\.", getwd(), data.dir)
  ))
}
if (!dir.exists(out.dir)) dir.create(paste0(data.dir, out.dir))
```

Define some global variables

```{r global_vars}
dat.TZ <- "US/Eastern"
```

Explore the data set

```{r explore}
names(DET)
str(DET)
dim(DET)
head(DET)
table(DET$Tidal.Phase)
table(DET$Shark, DET$Tidal.Phase)
table(DET$Shark)
```

Housekeeping and tidy up

```{r housekeeping}
DET %<>%
  mutate(Datetime = as.POSIXct(Datetime,
                               format = "%m/%d/%y %H:%M",
                               tz = dat.TZ
  )) %>%
  rename(
    Lat = N,
    Lon = W,
    T.Ph = Tidal.Phase
  ) %>%
  select(Datetime, Shark, T.Ph, Lat, Lon) %>% # dropped 2 variables (Date, Time)
  arrange(Shark, Datetime) # df size: 1308 x 5

write.csv(x = DET, file = "TracksCleaned.csv", row.names = FALSE) # Could load this directly here
```

Convert lonlat to UTM

```{r coord_UTM}
# First convert coordinate sets to SpatialPoints and project
cord.dec <- SpatialPoints(cbind(DET$Lon, DET$Lat),
                          proj4string = CRS("+proj=longlat")
)

# Transform to UTM by setting the EPSG to 32617 for WGS 84, UTM zone 17, northern hemisphere. This is where Bimini is located.
cord.UTM <- as.data.frame(spTransform(cord.dec, CRS("+init=epsg:32617")))
colnames(cord.UTM) <- c("NewEastingUTM", "NewNorthingUTM")
DET <- cbind(DET, cord.UTM) # 1308 x 7
```

Construct movement models per individual. 

Some notes regarding the 'move package and construction of movement models:
Several arguments need to be used to run the model.
1. Window size: corresponds with number of locations and moves along a given trajectory to estimate the MA parameter within defined subsections of the path. This increases the ability to detect breakpoints where changes in behaviour occur. The window size should relate to what kind of behaviours the model is desired to identify e.g., a window size of 23 means the sliding window is moved every 23 locations or every 23 hours (has to do with sampling interval)
2. Margin: motion variance based on only the middle section of the trajectory; the ends of the movement trajectory where no changes are allowed because at some stage you want to have a few locations to base your estimation of the variance on and how many locations in either side of the window we use for this, is called the margin. Smaller values for window size and margin is expected to give a higher frequency of behavioural changes; make these large for looking at migrations.
3. The raster dictates the grid cell size for the UD to be calculated per grid cell per individual. Create the raster of certain size that matches with coordinates used to make the move object
4. Extent: is incorporated if there are animal locations that border the edges of the raster.

A dBBMM is nor run if total detections of individual < window size (default value, 31). Below code checks and filters individuals with insufficient data. Below we set window size arbitrarily to 23

```{r filter_data}
check1 <- DET %>%
  group_by(Shark) %>%
  summarise(relocations = length(Datetime))
check1
check2 <- filter(check1, relocations > 23) # filter: removed 2 rows (14%), 12 rows remaining
check2

if (length(check1$Shark) != length(check2$Shark)) {
  DET <- semi_join(DET, check2) # Joining, by = "Shark". semi_join: added no columns
  check1 <- DET %>%
    group_by(Shark) %>%
    summarise(relocations = length(Datetime))
  check1
  check2 <- filter(check1, relocations > 23) # filter: no rows removed
  length(check1$Shark) == length(check2$Shark)
} # DET: 1287 x 7
```

In the next R code we create per individual a move object, project it, construct a dBBMM, calculate the volume area within the 50% and 95% contours and finally save the outcome as ASCII for plotting in an external GIS software.

```{r construct_dBMMMM}
bb <- list()
bb.list <- list()

DET %<>%
  tidyr::drop_na(Shark) %>%
  group_by(Shark) %>%
  distinct(Datetime, .keep_all = TRUE) %>% # distinct (grouped): removed one row (<1%), 1,286 rows remaining
  # prevents duplicate Datetime crash in move() later
  ungroup() # 1286 x 7 after removing as.numeric above

# Loop through all unique tags
counter <- 0
for (i in unique(DET$Shark)) { # i <- unique(DET$Shark)[1]
  
  # Print individual
  counter <- counter + 1
  print(paste0(
    "processing ", which(unique(DET$Shark) %in% i),
    " of ", length(unique(DET$Shark))
  ))
  
  # Filter individual data
  DET.i <- DET[DET$Shark == i, ]
  
  # create move object
  move.i <- move(
    x = DET.i$Lon,
    y = DET.i$Lat,
    time = DET.i$Datetime,
    proj = CRS("+proj=longlat +datum=WGS84"),
    data = DET.i,
    animal = DET.i$Shark,
    sensor = "VR2W"
  )
  
  # Check the current projection
  proj4string(move.i) # "+proj=longlat +datum=WGS84 +no_defs"
  
  # Incorporate uncertainty in the model by including a location error.
  # From communication with Rob, the gps location of a shark is estimated, from:
  # the boat coordinates, bearing and distance estimate, to be 1 m.
  move.i$LocationError <- 1 # 1 m: gps loc of shark inferred from boat coord + bearing + distance estimate
  
  # Convert projection to Azimuthal Equi-Distance projection (aeqd)
  r.i <- spTransform(move.i, center = TRUE)
  
  # Make sure it changed correctly
  proj4string(r.i) # "+proj=aeqd +lat_0=24.75136 +lon_0=-36.01593 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs"
  
  # Calculate time lag between consecutive detections.
  # Obviously there is no time lag for the first detection, so we need to tell R this.
  # Knowing time lags in acoustic telemetry is important, as the motion variance is based on the
  # time difference b/w detections at consecutive locations i.e. larger time lag creates a wider
  # bridge where the animal could've been and therefore potentially inflates the motion variance.
  # Below code deals with this issue by identifying the location and number of detections with
  # large time gaps. Below we will use an arbitrary value of 2 h.
  TimeDiff <- timeLag(r.i, units = "hours")
  r.i$TimeDiff <- append(0, TimeDiff)
  long <- which(r.i$TimeDiff > 2)
  
  # Make a raster for the UD to plot into. Start with UTM.
  # These coordinates need to be big enough to cover your data.
  # May need to expand x and y ranges (i.e. the "e" variable below) if you encounter errors when constructing the DBBMM in the next code chunk.
  # NOTE: "xUTM" grid should be larger than the "x" i.e. lower minimums and higher.
  # The variable 'e' influences the extent.
  # The resolution determines the grid size.
  # Finer resolution/grid size (in m) i.e. lower value means longer computation time. May need/want to play with this value too.
  # e <- 80 * 1000 # make e a function of range of extent as %
  
  # Error in .local(object, raster, location.error = location.error, ext = ext,  :
  # Lower x grid not large enough, consider extending the raster in that direction or enlarging the ext argument
  # make buffpct larger
  buffpct <- 30 # buffer extent as a %
  buffpct <- buffpct / 100
  xUTM.i <- raster(
    xmn = min(DET$NewEastingUTM, na.rm = TRUE) - ((max(DET$NewEastingUTM, na.rm = TRUE) - min(DET$NewEastingUTM, na.rm = TRUE)) * buffpct),
    xmx = max(DET$NewEastingUTM, na.rm = TRUE) + ((max(DET$NewEastingUTM, na.rm = TRUE) - min(DET$NewEastingUTM, na.rm = TRUE)) * buffpct),
    ymn = min(DET$NewNorthingUTM, na.rm = TRUE) - ((max(DET$NewNorthingUTM, na.rm = TRUE) - min(DET$NewNorthingUTM, na.rm = TRUE)) * buffpct),
    ymx = max(DET$NewNorthingUTM, na.rm = TRUE) + ((max(DET$NewNorthingUTM, na.rm = TRUE) - min(DET$NewNorthingUTM, na.rm = TRUE)) * buffpct),
    crs = CRS("+proj=utm +zone=17 +datum=WGS84"),
    resolution = 50
  ) # 50
  
  # We now need to reproject this into AEQD. Make a dummy object to get the correct projection.
  x.i <- raster(
    xmn = min(DET$NewEastingUTM),
    xmx = max(DET$NewEastingUTM),
    ymn = min(DET$NewNorthingUTM),
    ymx = max(DET$NewNorthingUTM),
    crs = CRS("+proj=utm +zone=17 +datum=WGS84")
  )
  proj4string(x.i) # "+proj=utm +zone=17 +datum=WGS84 +units=m +no_defs"
  
  # Use that to reproject UTM to AEQD
  # ?projectExtent # project the values of a Raster object to a new Raster object with another projection (CRS), i.e. projectExtent(from, to, ...))
  newTemplate <- projectExtent(xUTM.i, proj4string(x.i))
  rm(x.i)
  newTemplate # get the number of pixels in newTemplate and write that number into the next function. This is an empty raster.
  # class      : RasterLayer
  # dimensions : 142615, 187156, 26691252940  (nrow, ncol, ncell)
  # resolution : 50, 50  (x, y)
  # extent     : 593395.5, 9951195, 2545826, 9676576  (xmin, xmax, ymin, ymax)
  # crs        : +proj=utm +zone=17 +datum=WGS84 +units=m +no_defs
  
  # Give newTemplate some values. Make Rep equal to the ncell dimension
  ones <- rep(1, ncell(newTemplate))
  xAEQD.i <- setValues(newTemplate, ones)
  rm(newTemplate)
  rm(ones)
  xAEQD.i
  # class      : RasterLayer
  # dimensions : 3270, 3245, 10611150  (nrow, ncol, ncell)
  # resolution : 50, 50  (x, y)
  # extent     : 594830.7, 757080.7, 2763971, 2927471  (xmin, xmax, ymin, ymax)
  # crs        : +proj=utm +zone=17 +datum=WGS84 +units=m +no_defs
  # source     : memory
  # names      : layer
  # values     : 1, 1  (min, max)
  
  # Reproject the move object r into AEQD
  rNew.i <- spTransform(r.i, proj4string(xAEQD.i))
  rNew.i
  # class       : Move
  # features    : 37
  # extent      : 674830.7, 677094.8, 2843987, 2847471  (xmin, xmax, ymin, ymax)
  # crs         : +proj=utm +zone=17 +datum=WGS84 +units=m +no_defs
  # variables   : 7
  # names       :   Datetime,      Lat,       Lon,    NewEastingUTM,   NewNorthingUTM, LocationError,         TimeDiff
  # min values  : 1409777400, 25.70323, -79.25719, 674830.719845252, 2843986.90740363,             1,                0
  # max values  : 1410148680, 25.73457, -79.23457, 677094.847481247, 2847470.56026671,             1, 31.1666666666667
  # timestamps  : 2014-09-03 16:50:00 ... 2014-09-07 23:58:00 Time difference of 4 days  (start ... end, duration)
  # sensors     : VR2W
  # indiv. data : Shark, T.Ph
  # indiv. value: E07 L
  # date created: 2021-08-25 01:42:43
  
  # We need to make sure that the projection of the move object is in the same format as our raster. Check below.
  proj4string(xAEQD.i) # "+proj=utm +zone=17 +datum=WGS84 +units=m +no_defs"
  proj4string(rNew.i) # "+proj=utm +zone=17 +datum=WGS84 +units=m +no_defs"
  proj4string(xAEQD.i) == proj4string(rNew.i) # TRUE
  
  # Below we exclude the data points that are 'long' i.e. create a large time gap. move::burst ?
  bursted <- burst(
    rNew.i,
    c("normal", "long")[1 + (timeLag(rNew.i, units = "hours") > 2)]
  )
  rm(rNew.i)
  # There are 2 types of burst: "normal" and "long". You can select for these in the dbbmm by selecting the factor level in the burstType command.
  
  # Construct the model. The time.step should reflect the ping frequency of the tag (in minutes)
  bursted_dbbmm <- brownian.bridge.dyn(bursted,
                                       burstType = "normal",
                                       raster = xAEQD.i,
                                       location.error = "LocationError",
                                       time.step = 5,
                                       ext = 3,
                                       window.size = 23
  )
  rm(bursted)
  rm(xAEQD.i)
  
  # Re-standardize (Dr. Kranstauber's trouble shooting solution).
  # Occurring errors are "due to limits of accuracy during calculations.
  # Given the error is really small (<.000001 %) I would not worry to much and re-standardize".
  # Then aggregate UD segments.
  tmp <- calc(bursted_dbbmm, sum) # raster::calc :Calculate values for a new Raster* object from another Raster* object
  # using a formula. returns a RasterLayer if fun returns a single value (e.g. sum)
  rm(bursted_dbbmm)
  bb <- new(".UD", tmp / sum(values(tmp))) # new() creates object from Class ("UD.")
  rm(tmp)
  
  # Export aggregated individual UDs to as ascii files for further exploration/spatial analysis in GIS software.
  # Needed for when the aim is to plot population-level and normalized UDs per species.
  # asc <- writeRaster(bb,
  #                   paste0(data.dir, out.dir, filename = i, ".asc"),
  #                   format = "ascii",
  #                   datatype = "FLT4S",
  #                   bylayer = T,
  #                   overwrite = T)
  
  # Calculate volume area (m^2) within 50% (core) and 95% (general use) contours. Note: absolute scale
  area.50 <- sum(values(getVolumeUD(bb) <= .50))
  area.95 <- sum(values(getVolumeUD(bb) <= .95))
  
  # Combine in single df
  area.ct <- data.frame(
    core.use = area.50,
    general.use = area.95
  )
  
  # Add Shark id
  area.ct$Shark <- i
  
  # Put in list
  bb.list[[counter]] <- area.ct
  bb.list
  gc()
}

# Put everything in a data.frame
md <- bind_rows(bb.list,
                .id = "column_label"
)

write.csv(md,
          file = paste0(data.dir, out.dir, "Lemon_VolumeArea.csv"),
          row.names = FALSE
)

# Scale and sum individual rasters, followed by a rescaling to obtain an aggregated UD (.asc)
print(Sys.info()["nodename"])
if (grepl("aurits", Sys.info()["nodename"])) {
  work.dir <- "~/Documents/Science/Projects/Rob Bullock - Bimini/"
}
if (grepl("nautilus", Sys.info()["nodename"]) | grepl("Poseidon", Sys.info()["nodename"]) | grepl("aquarius", Sys.info()["nodename"])) {
  work.dir <- "/home/simon/Dropbox/PostDoc Work/Rob Bullock accelerometer Lemons 2020.09/"
}

source(paste0(work.dir, "scaleraster.R"))
scaleraster(path = paste0(data.dir, out.dir))
```

Now we're ready for the final step: plotting!

```{r plot}
# Import raster
# lemons.ras <- raster(paste0(work.dir, "/data/dBBMM ASCII/Scaled/All_Rasters_Scaled.asc")) # mo
# lemons.ras <- raster(paste0(work.dir, "/dBBMM ASCII/Scaled/All_Rasters_Scaled.asc")) # si
# lemons.ras
# plot(sqrt(lemons.ras)) # sqrt inflates the values to make it easier to view
# plot(lemons.ras) # fix this nor plotting why?? SD

library(stars)
lemons.ras <- read_stars(paste0(work.dir, "/dBBMM ASCII/Scaled/All_Rasters_Scaled.asc")) %>% # si directory
  st_set_crs(2958) %>%
  st_transform(4326)

# lemons.ras2
# plot(sqrt(lemons.ras2)) # sqrt inflates the values to make it easier to view
# plot(lemons.ras2) # fix this nor plotting why?? SD

# # Set projection
# crs(lemons.ras) <- "+init=epsg:32617"
# lemons.ras
# 
# lemons.poly <- rasterToPolygons(trim(lemons.ras, values = 0))
# 
# # Extract UD values column
# layer <- lemons.poly@data
# 
# # Transform raster object to data frame
# lemon.poly.df <- fortify(lemons.poly)
# 
# # Merge
# lemon.poly.df <- cbind(lemon.poly.df, layer)
# 
# # Transform to simple features and change crs
# lemon.poly.df.sf <- st_as_sf(lemon.poly.df, coords = c("long", "lat"), crs = 2958) %>%
#   st_transform(4326)

# # Get map function makes a call to online databases and retrieves a map which is defined by the bounding box
# test <- get_map(bbox(extent(lemon.poly.df.sf)), zoom = 12)
# test <- get_map(bbox(extent(lemon.poly.df.sf2)), zoom = 12)
# 
# 
# # Plot in projected CRS
# ggplot() +
#   geom_raster(data = lemon.poly.df.sf, aes(x = x, y = y, fill = layer))
library(devtools)
install_github("SimonDedman/gbm.auto")
library(gbm.auto)
dir.create(paste0(out.dir, "basemap"))
bounds <- st_bbox(lemons.ras) %>% as.vector() # xmin      ymin      xmax      ymax 
bounds <- bounds[c(1, 3, 2, 4)] # c(xmin,xmax,ymin,ymax)
crop_map <- gbm.basemap(bounds = bounds,
                        res = "f",
                        # getzip = paste0(work.dir, out.dir, "basemap/GSHHS_shp"), # comment out first time, uncomment subsequent
                        savedir = paste0(work.dir, out.dir, "basemap"),
                        returnsf = TRUE)
# crop_map <- st_read(dsn = paste0(work.dir, out.dir, "basemap/CroppedMap/Crop_Map.shp"),
#                     layer = paste0("Crop_Map"),
#                     quiet = TRUE) # read in worldmap

ggplot() +
  geom_stars(data = sqrt(lemons.ras)) + # geom_stars only works for objects with raster or vector geometries
  geom_sf(data = crop_map, colour = "black", fill = "grey") + # coastline basemap
  coord_sf(xlim = bounds[1:2], ylim = bounds[3:4], expand = FALSE) +
  scale_fill_viridis_c() +
  ggtitle("dBBMM title, ideally dynamic based on data",
          subtitle = "inc subtitle if worthwhile") +
  xlab("Longitude") +
  ylab("Latitude") +
  theme_minimal()

# geom_sf(
#   data = lemon.poly.df.sf, aes(group = id),
#   fill = "purple"
# ) +
#   scale_alpha(range = c(0, 1), "Utilization\nDistribution")
```

Now that we have constructed individual movement models for complete movement trajectories, below we will do the same, but now we will discern different tidal phases when constructing the models.

```{r dir}
# set path to general folders where output files will be written
if (!dir.exists("dBBMM ASCII/Tide")) dir.create("dBBMM ASCII/Tide")
out.dir_h <- "dBBMM ASCII/Tide/H"
if (!dir.exists(out.dir_h)) dir.create(paste0(data.dir, out.dir_h))
out.dir_l <- "dBBMM ASCII/Tide/L"
if (!dir.exists(out.dir_l)) dir.create(paste0(data.dir, out.dir_l))
out.dir_m <- "dBBMM ASCII/Tide/M"
if (!dir.exists(out.dir_m)) dir.create(paste0(data.dir, out.dir_m))
```

```{r construct_tidal_dbbmm}
# Loop through the different tidal phases
for (i in unique(DET$T.Ph)) { # "H" "M" "L"
  
  # Filter individual tide data
  DET.t <- DET[DET$T.Ph == i, ]
  
  # remove sharks with insufficient movement data (identical to code L113-L128)
  check1 <- DET.t %>%
    group_by(Shark) %>%
    summarise(relocations = length(Datetime))
  check1
  check2 <- filter(check1, relocations > 23)
  check2
  
  if (length(check1$Shark) != length(check2$Shark)) {
    DET.t <- semi_join(DET.t, check2)
    check1 <- DET.t %>%
      group_by(Shark) %>%
      summarise(relocations = length(Datetime))
    check1
    check2 <- filter(check1, relocations > 23)
    length(check1$Shark) == length(check2$Shark)
  }
  
  # Loop through all unique tags
  bb.list <- list()
  counter <- 0
  for (j in unique(DET.t$Shark)) {
    # Print individual
    counter <- counter + 1
    print(paste0(
      "processing ", which(unique(DET.t$Shark) %in% j),
      " of ", length(unique(DET.t$Shark)),
      " tags, tide = ", i,
      " (", which(unique(DET$T.Ph) %in% i),
      " of ", length(unique(DET$T.Ph)), ")"
    ))
    
    # Filter individual data
    DET.i <- DET.t[DET.t$Shark == j, ]
    
    # create move object
    move.i <- move(
      x = DET.i$Lon,
      y = DET.i$Lat,
      time = DET.i$Datetime,
      proj = CRS("+proj=longlat +datum=WGS84"),
      data = DET.i,
      animal = DET.i$Shark,
      sensor = "VR2W"
    )
    # Warning: Unknown or uninitialised column: `citation`.
    # Warning: Setting row names on a tibble is deprecated.
    
    # Check the current projection
    proj4string(move.i) # "+proj=longlat +datum=WGS84 +no_defs"
    
    # Incorporate uncertainty in the model by including a location error.
    # From communication with Rob, the gps location of a shark is estimated,
    # from the boat coordinates, bearing and distance estimate, to be 1 m.
    move.i$LocationError <- 1 # 1 m: gps loc of shark inferred from boat coord + bearing + distance estimate
    
    # Convert projection to Azimuthal Equi-Distance projection (aeqd)
    r.i <- spTransform(move.i, center = TRUE)
    
    # Make sure it changed correctly
    proj4string(r.i) # "+proj=aeqd +lat_0=25.73054 +lon_0=-79.248155 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs"
    
    # Calculate time lag between consecutive detections. Obviously there is no time lag for the first detection, so we need to tell R this. Knowing time lags in acoustic telemetry is important, as the motion variance is based on the time difference b/w detections at consecutive locations i.e. larger time lag creates a wider bridge where the animal could've been and therefore potentially inflates the motion variance. Below code deals with this issue by identifying the location and number of detections with large time gaps. Below we will use an arbitrary value of 2 h.
    TimeDiff <- timeLag(r.i, units = "hours")
    r.i$TimeDiff <- append(0, TimeDiff)
    long <- which(r.i$TimeDiff > 2)
    
    # Make a raster for the UD to plot into. Start with UTM. These coordinates need to be big enough to cover your data. May need to expand x and y ranges if you encounter errors when constructing the DBBMM in the next code chunk. NOTE: "xUTM" grid should be larger than the "x" i.e. lower minimums and higher. The resolution determines the grid size. The variable 'e' influences the extent. Finer resolution/grid size (in m) i.e. lower value means longer computation time.
    
    buffpct <- 10 # buffer extent as a %
    buffpct <- buffpct / 100
    xUTM.i <- raster(
      xmn = min(DET$NewEastingUTM, na.rm = TRUE) - ((max(DET$NewEastingUTM, na.rm = TRUE) - min(DET$NewEastingUTM, na.rm = TRUE)) * buffpct),
      xmx = max(DET$NewEastingUTM, na.rm = TRUE) + ((max(DET$NewEastingUTM, na.rm = TRUE) - min(DET$NewEastingUTM, na.rm = TRUE)) * buffpct),
      ymn = min(DET$NewNorthingUTM, na.rm = TRUE) - ((max(DET$NewNorthingUTM, na.rm = TRUE) - min(DET$NewNorthingUTM, na.rm = TRUE)) * buffpct),
      ymx = max(DET$NewNorthingUTM, na.rm = TRUE) + ((max(DET$NewNorthingUTM, na.rm = TRUE) - min(DET$NewNorthingUTM, na.rm = TRUE)) * buffpct),
      crs = CRS("+proj=utm +zone=17 +datum=WGS84"),
      resolution = 50
    ) # 50
    
    # We now need to reproject this into AEQD. Make a dummy object to get the correct projection.
    x.i <- raster(
      xmn = min(DET$NewEastingUTM),
      xmx = max(DET$NewEastingUTM),
      ymn = min(DET$NewNorthingUTM),
      ymx = max(DET$NewNorthingUTM),
      crs = CRS("+proj=utm +zone=17 +datum=WGS84")
    )
    proj4string(x.i) # "+proj=utm +zone=17 +datum=WGS84 +units=m +no_defs"
    
    # Use that to reproject UTM to AEQD
    # ?projectExtent # project the values of a Raster object to a new Raster object with another projection (CRS), i.e.     projectExtent(from, to, ...))
    newTemplate <- projectExtent(xUTM.i, proj4string(x.i))
    rm(xUTM.i)
    rm(x.i)
    newTemplate # get the number of pixels in newTemplate and write that number into the next function. This is an empty raster.
    # class      : RasterLayer
    # dimensions : 3224, 3207, 10339368  (nrow, ncol, ncell)
    # resolution : 50, 50  (x, y)
    # extent     : 595559.2, 755909.2, 2766404, 2927604  (xmin, xmax, ymin, ymax)
    # crs        : +proj=utm +zone=17 +datum=WGS84 +units=m +no_defs
    
    # Give newTemplate some values. Make Rep equal to the ncell dimension
    ones <- rep(1, ncell(newTemplate))
    xAEQD.i <- setValues(newTemplate, ones)
    rm(newTemplate)
    rm(ones)
    xAEQD.i
    
    # Reproject the move object r into AEQD
    rNew.i <- spTransform(r.i, proj4string(xAEQD.i))
    rNew.i
    # class      : RasterLayer
    # dimensions : 3224, 3207, 10339368  (nrow, ncol, ncell)
    # resolution : 50, 50  (x, y)
    # extent     : 595559.2, 755909.2, 2766404, 2927604  (xmin, xmax, ymin, ymax)
    # crs        : +proj=utm +zone=17 +datum=WGS84 +units=m +no_defs
    # source     : memory
    # names      : layer
    # values     : 1, 1  (min, max)
    
    # We need to make sure that the projection of the move object is in the same format as our raster. Check below.
    proj4string(xAEQD.i) # "+proj=utm +zone=17 +datum=WGS84 +units=m +no_defs"
    proj4string(rNew.i) # "+proj=utm +zone=17 +datum=WGS84 +units=m +no_defs"
    proj4string(xAEQD.i) == proj4string(rNew.i) # TRUE
    
    # Below we exclude the data points that are 'long' i.e. create a large time gap.
    bursted <- burst(rNew.i, c("normal", "long")[1 + (timeLag(rNew.i, units = "hours") > 2)])
    rm(rNew.i)
    # There are 2 types of burst: "normal" and "long".
    # You can select for these in the dbbmm by selecting the factor level in the burstType command.
    
    # Construct the model. The time.step should reflect the ping frequency of the tag (in minutes)
    bursted_dbbmm <- brownian.bridge.dyn(bursted,
                                         burstType = "normal",
                                         raster = xAEQD.i,
                                         location.error = "LocationError",
                                         time.step = 5,
                                         ext = 3,
                                         window.size = 23
    )
    rm(bursted)
    rm(xAEQD.i)
    # Warning: Some burst are omitted for variance calculation since there are not segements of interest
    
    # Re-standardize (Dr. Kranstauber's trouble shooting solution). Occurring errors are
    # "due to limits of accuracy during calculations. Given the error is really small (<.000001 %)
    # I would not worry to much and re-standardize".
    # Then aggregate UD segments.
    tmp <- calc(bursted_dbbmm, sum)
    rm(bursted_dbbmm)
    bb <- new(".UD", tmp / sum(values(tmp)))
    rm(tmp)
    
    # Export aggregated individual UDs to as ascii files for further exploration/spatial analysis in GIS software.
    # Needed for when the aim is to plot population-level and normalized UDs per species.
    asc <- writeRaster(bb,
                       paste0(data.dir, out.dir, "Tide/", i, "/", filename = j, ".asc"),
                       format = "ascii",
                       datatype = "FLT4S",
                       bylayer = T,
                       overwrite = T
    )
    
    # Calculate volume area (m^2) within 50% (core) and 95% (general use) contours
    area.50 <- sum(values(getVolumeUD(bb) <= .50))
    area.95 <- sum(values(getVolumeUD(bb) <= .95))
    rm(bb)
    # Combine in single df
    area.ct <- data.frame(core.use = area.50, general.use = area.95) # why change names?
    
    # Add Shark id
    area.ct$Shark <- j
    
    # Put in list
    bb.list[[counter]] <- area.ct
    bb.list
    gc()
  }
  
  # Put everything in a data.frame
  md <- bind_rows(bb.list, .id = "column_label")
  
  write.csv(
    x = md,
    file = paste0(data.dir, out.dir, "Tide/Lemon_VolumeArea_", i, ".csv"),
    row.names = FALSE
  )
  
  # Normalise rasters
  normaliseraster(path = paste0(data.dir, out.dir))
}
```
